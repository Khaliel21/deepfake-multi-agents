# ğŸ¤– Deep Fake Agent Â· Multi-Agent GenAI Pipeline

<p align="center">
  <img src="assets/banner.png" alt="Deep Fake Agent Banner" width="100%">
</p>


> A powerful and modular multi-agent system that simulates the creation and detection of synthetic video content using GenAI tools like LangGraph, LangChain, HuggingFace, and more. Built for research, prototyping, and real-world experimentation. ğŸ§ ğŸ¥

## ğŸš€ Overview

**Deep Fake Agent** is a Generative AI pipeline that replicates how an AI system might autonomously generate fake content.  
It uses a team of AI agents ğŸ¤– that communicate over a neural-like network to:

- Generate content (script, voice, video)
- Analyze and evaluate it
- And finally determine if itâ€™s **FAKE** or not.

The entire flow is orchestrated via **LangGraph**, and each agent has a clearly defined, typed role within the pipeline.

---

## âœ¨ Features

- ğŸ“ Script generation via LLM
- ğŸ“„ Script summarization
- ğŸ”Š Voice generation using gTTS
- ğŸ¬ Video creation from text and audio
- ğŸ•µï¸ Deepfake detection using HuggingFace models
- ğŸ¤– Modular agents using LangChain Expression Language (LCEL)
- âœ… Fully typed data flow with Pydantic
- ğŸªµ Detailed logs at each stage

---

## ğŸ§  Agent Architecture

The pipeline is composed of 6 core agents ğŸ¤– that communicate sequentially as part of the LangGraph flow:

1. ğŸš€ **Start**  
   Initializes the flow and passes the initial state.

2. ğŸ¤– **Script Agent**  
   Generates a text script using a language model (LLM).

3. ğŸ“„ **Summary Agent**  
   Summarizes the script to prepare it for narration.

4. ğŸ”Š **Voice Agent**  
   Converts the summary to voice using gTTS.

5. ğŸ¬ **Video Agent**  
   Combines the generated voice with visuals into a video.

6. ğŸ•µï¸ **DeepFake Detector**  
   Analyzes the video using AI models to detect whether itâ€™s fake or real.

7. âœ… **Final Checker**  
   Collects and formats the result of the classification.

8. ğŸ **End**  
   Ends the pipeline and returns the result.

---

## ğŸ§° Tech Stack

The project leverages a combination of GenAI frameworks, ML APIs, and multimedia tools:

- ğŸ” **LangGraph + LangChain**  
  Used for agent orchestration, control flow, and building modular LCEL pipelines.

- ğŸ§© **Pydantic**  
  Provides structured data models for clean input/output between agents.

- ğŸ—£ï¸ **gTTS**  
  Enables lightweight, offline text-to-speech generation.

- ğŸï¸ **MoviePy + Pillow**  
  Used for video frame rendering, adding voiceover, and generating video clips.

- ğŸ¤– **HuggingFace Inference API** (for Deepfake detection):  
  - [`dima806/deepfake_vs_real_image_detection`](https://huggingface.co/dima806/deepfake_vs_real_image_detection)  
  - [`prithivMLmods/Deep-Fake-Detector-v2-Model`](https://huggingface.co/prithivMLmods/Deep-Fake-Detector-v2-Model)  
  - [`prithivMLmods/Deepfake-Real-Class-Siglip2`](https://huggingface.co/prithivMLmods/Deepfake-Real-Class-Siglip2)

---

## ğŸ“ Project Structure

Here's an overview of the project folder structure:

- `agents/` â€“ All LCEL agents (script, summary, voice, video, deepfake, checker)
- `utils_graph/` â€“ Helper modules (media tools, LangChain utils)
- `config/` â€“ Settings and environment variables
- `assets/` â€“ Static resources (images, icons, etc.)
- `data/` â€“ Prompt text templates
- `main.py` â€“ Entry point for executing the pipeline
- `template.py` â€“ Video layout logic
- `load_env.py` â€“ Loads environment variables
- `uni_test_main.py` â€“ Runs the full flow as a unit test
- `requirements.txt` â€“ Python dependencies
- `README.md` â€“ Youâ€™re reading it ğŸ˜

---

## âš™ï¸ Installation

To run this project locally:

1. Clone the repository:

```bash
git clone https://github.com/Khaliel21/deepfake-multi-agents.git
cd deepfake-multi-agents